/*
 ***********************************************************************************************************************
 *
 *  Copyright (c) 2014-2018 Advanced Micro Devices, Inc. All Rights Reserved.
 *
 *  Permission is hereby granted, free of charge, to any person obtaining a copy
 *  of this software and associated documentation files (the "Software"), to deal
 *  in the Software without restriction, including without limitation the rights
 *  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 *  copies of the Software, and to permit persons to whom the Software is
 *  furnished to do so, subject to the following conditions:
 *
 *  The above copyright notice and this permission notice shall be included in all
 *  copies or substantial portions of the Software.
 *
 *  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 *  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 *  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 *  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 *  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 *  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 *  SOFTWARE.
 *
 **********************************************************************************************************************/

#include "core/device.h"
#include "core/g_palSettings.h"
#include "core/platform.h"
#include "core/hw/gfxip/gfxDevice.h"
#include "core/hw/gfxip/pipeline.h"
#include "palFile.h"
#include "palPipelineAbiProcessorImpl.h"

#include "core/devDriverUtil.h"

using namespace Util;

namespace Pal
{

// The generator describes the pipeline is generated by PAL or extern tool. Driver doesn't need to validate the
// buildId or settingsHash if it's generated by an extern tool.
enum class SerializedPipelineGenerator : uint32
{
    Pal         = 0, // The pipeline is generated by Pal driver.
    ExternTool  = 1, // The pipeline is generated by extern tool.
};

// Represents information for compatibility checks when loading a stored pipeline.  If a pipeline was stored by a
// different version of PAL than the version loading it, the load will fail.
struct SerializedPipelineHeader
{
    uint32        deviceId;       // As in DeviceProperties.
    BuildUniqueId buildId;        // 16-byte identifier for a particular PAL build (typically a time-stamp of the
                                  // compiled library that serialized the pipeline.
    MetroHash::Hash settingsHash; // Hash of the active PAL settings this pipeline was compiled with.

    // Serialize the base addresses of each VA range partition since some of those are baked into compiled shaders.
    gpusize vaRangeBaseAddr[static_cast<uint32>(VaRange::Count)];

    SerializedPipelineGenerator generator; // Indicates what generated this pipeline.
};

// Private structure used to store/load a data members of a pipeline object.
struct SerializedData
{
    size_t          totalGpuMemSize;
    PipelineInfo    info;
    ShaderMetadata  shaderMetadata;
};

// =====================================================================================================================
Pipeline::Pipeline(
    Device* pDevice,
    bool    isInternal)  // True if this is a PAL-owned pipeline (i.e., an RPM pipeline).
    :
    m_pDevice(pDevice),
    m_gpuMem(),
    m_gpuMemSize(0),
    m_pPipelineBinary(nullptr),
    m_pipelineBinaryLen(0),
    m_apiHwMapping()
{
    m_flags.value      = 0;
    m_flags.isInternal = isInternal;

    m_apiHwMapping.u64All = 0;

    memset(&m_info, 0, sizeof(m_info));
    memset(&m_shaderMetaData, 0, sizeof(m_shaderMetaData));
    memset(&m_perfDataInfo, 0, sizeof(m_perfDataInfo));
}

// =====================================================================================================================
Pipeline::~Pipeline()
{
    if (m_gpuMem.IsBound())
    {
        m_pDevice->MemMgr()->FreeGpuMem(m_gpuMem.Memory(), m_gpuMem.Offset());
        m_gpuMem.Update(nullptr, 0);
    }

    PAL_SAFE_FREE(m_pPipelineBinary, m_pDevice->GetPlatform());
}

// =====================================================================================================================
// Destroys a pipeline object allocated via a subclass' CreateInternal()
void Pipeline::DestroyInternal()
{
    PAL_ASSERT(IsInternal());

    Platform*const pPlatform = m_pDevice->GetPlatform();
    Destroy();
    PAL_FREE(this, pPlatform);
}

// =====================================================================================================================
// Allocates GPU memory for this pipeline and uploads the code and data contain in the ELF binary to it.  Any ELF
// relocations are also applied to the memory during this operation.
Result Pipeline::PerformRelocationsAndUploadToGpuMemory(
    const AbiProcessor&       abiProcessor,
    const CodeObjectMetadata& metadata,
    gpusize*                  pCodeGpuVirtAddr,
    gpusize*                  pDataGpuVirtAddr)
{
    PAL_ASSERT((pCodeGpuVirtAddr != nullptr) && (pDataGpuVirtAddr != nullptr));

    constexpr size_t GpuMemByteAlign = 256;

    GpuMemoryCreateInfo createInfo = { };
    createInfo.alignment = GpuMemByteAlign;
    createInfo.vaRange   = VaRange::DescriptorTable;
    createInfo.heaps[0]  = GpuHeapLocal;
    createInfo.heaps[1]  = GpuHeapGartUswc;
    createInfo.heapCount = 2;
    createInfo.priority  = GpuMemPriority::High;

    GpuMemoryInternalCreateInfo internalInfo = { };
    internalInfo.flags.alwaysResident = 1;

    const void* pCodeBuffer = nullptr;
    size_t      codeLength  = 0;
    abiProcessor.GetPipelineCode(&pCodeBuffer, &codeLength);

    createInfo.size = codeLength;

    const void* pDataBuffer   = nullptr;
    size_t      dataLength    = 0;
    gpusize     dataAlignment = 0;

    abiProcessor.GetData(&pDataBuffer, &dataLength, &dataAlignment);

    if (dataLength > 0)
    {
        createInfo.size += Pow2Align(dataLength, dataAlignment);
    }

    const gpusize perfDataOffset = createInfo.size;
    createInfo.size += PerformanceDataSize(metadata);

    GpuMemory* pGpuMem = nullptr;
    gpusize    offset  = 0;
    Result result = m_pDevice->MemMgr()->AllocateGpuMem(createInfo, internalInfo, false, &pGpuMem, &offset);
    if (result == Result::Success)
    {
        m_gpuMemSize = createInfo.size;
        m_gpuMem.Update(pGpuMem, offset);

        void* pMappedPtr = nullptr;
        result = m_gpuMem.Map(&pMappedPtr);
        if (result == Result::Success)
        {
            (*pCodeGpuVirtAddr) = m_gpuMem.GpuVirtAddr();
            memcpy(pMappedPtr, pCodeBuffer, codeLength);

            if (dataLength > 0)
            {
                void* pDataPtr = VoidPtrAlign(VoidPtrInc(pMappedPtr, codeLength), static_cast<size_t>(dataAlignment));

                (*pDataGpuVirtAddr) = ((*pCodeGpuVirtAddr) + Pow2Align(codeLength, dataAlignment));
                memcpy(pDataPtr, pDataBuffer, dataLength);

                // The for loop which follows is entirely non-standard behavior for an ELF loader, but is intended to
                // only be temporary code.
                for (uint32 s = 0; s < static_cast<uint32>(Abi::HardwareStage::Count); ++s)
                {
                    const Abi::PipelineSymbolType symbolType =
                        Abi::GetSymbolForStage(Abi::PipelineSymbolType::ShaderIntrlTblPtr,
                                               static_cast<Abi::HardwareStage>(s));

                    Abi::PipelineSymbolEntry symbol = { };
                    if (abiProcessor.HasPipelineSymbolEntry(symbolType, &symbol) &&
                        (symbol.sectionType == Abi::AbiSectionType::Data))
                    {
                        m_pDevice->GetGfxDevice()->PatchPipelineInternalSrdTable(
                            VoidPtrInc(pDataPtr,    static_cast<size_t>(symbol.value)), // Dst
                            VoidPtrInc(pDataBuffer, static_cast<size_t>(symbol.value)), // Src
                            static_cast<size_t>(symbol.size),
                            (*pDataGpuVirtAddr));
                    }
                } // for each hardware stage
                // End temporary code
            } // if dataLength > 0

            gpusize perfGpuAddr   = m_gpuMem.GpuVirtAddr() + perfDataOffset;
            size_t  currentOffset = static_cast<size_t>(perfDataOffset);
            for (uint32 i = 0; i < static_cast<uint32>(Abi::HardwareStage::Count); i++)
            {
                uint32 perfDataSize = 0;

                if (metadata.pipeline.hardwareStage[i].hasEntry.perfDataBufferSize)
                {
                    m_perfDataInfo[i].sizeInBytes = metadata.pipeline.hardwareStage[i].perfDataBufferSize;
                    m_perfDataInfo[i].cpuOffset   = currentOffset;
                    m_perfDataInfo[i].gpuVirtAddr = LowPart(perfGpuAddr);
                    memset(VoidPtrInc(pMappedPtr, m_perfDataInfo[i].cpuOffset), 0, perfDataSize);

                    perfGpuAddr   += perfDataSize;
                    currentOffset += perfDataSize;
                }
            }

            m_gpuMem.Unmap();
        }
    }

    return result;
}

// =====================================================================================================================
// Helper function for extracting the pipeline hash and per-shader hashes from pipeline metadata.
void Pipeline::ExtractPipelineInfo(
    const CodeObjectMetadata& metadata,
    ShaderType                firstShader,
    ShaderType                lastShader)
{
    m_info.compilerHash = metadata.pipeline.pipelineCompilerHash;
    PAL_ALERT(m_info.compilerHash == 0); // We don't expect the pipeline ABI to report a hash of zero.

    // Default the pipeline hash to the compiler hash. PAL pipelines that include additional state should override this
    // with a new hash composed of that state and the compiler hash.
    m_info.pipelineHash = m_info.compilerHash;

    for (uint32 s = static_cast<uint32>(firstShader); s <= static_cast<uint32>(lastShader); ++s)
    {
        Abi::ApiShaderType shaderType = static_cast<Abi::ApiShaderType>(s);

        const auto& shaderMetadata = metadata.pipeline.shader[s];

        m_info.shader[s].hash = { shaderMetadata.apiShaderHash[0], shaderMetadata.apiShaderHash[1] };
        m_apiHwMapping.apiShaders[s] = static_cast<uint8>(shaderMetadata.hardwareMapping);
    }
}

// =====================================================================================================================
// Query this pipeline's Bound GPU Memory.
Result Pipeline::QueryAllocationInfo(
    size_t*                   pNumEntries,
    GpuMemSubAllocInfo* const pGpuMemList)
{
    Result result = Result::ErrorInvalidPointer;

    if (pNumEntries != nullptr)
    {
        (*pNumEntries) = 1;

        if (pGpuMemList != nullptr)
        {
            pGpuMemList[0].offset     = m_gpuMem.Offset();
            pGpuMemList[0].pGpuMemory = m_gpuMem.Memory();
            pGpuMemList[0].size       = m_gpuMemSize;
        }

        result = Result::Success;
    }

    return result;
}

// =====================================================================================================================
// Extracts the binary shader instructions for a specific API shader stage.
Result Pipeline::GetShaderCode(
    ShaderType shaderType,
    size_t*    pSize,
    void*      pBuffer
    ) const
{
    Result result = Result::ErrorUnavailable;

    const ShaderStageInfo*const pInfo = GetShaderStageInfo(shaderType);
    if (pSize == nullptr)
    {
        result = Result::ErrorInvalidPointer;
    }
    else if (pInfo != nullptr)
    {
        PAL_ASSERT(pInfo->codeLength != 0); // How did we get here if there's no shader code?!

        if (pBuffer == nullptr)
        {
            (*pSize) = pInfo->codeLength;
            result   = Result::Success;
        }
        else if ((*pSize) >= pInfo->codeLength)
        {
            // To extract the shader code, we can re-parse the saved ELF binary and lookup the shader's program
            // instructions by examining the symbol table entry for that shader's entrypoint.
            AbiProcessor abiProcessor(m_pDevice->GetPlatform());
            result = abiProcessor.LoadFromBuffer(m_pPipelineBinary, m_pipelineBinaryLen);
            if (result == Result::Success)
            {
                const auto& symbol = abiProcessor.GetPipelineSymbolEntry(
                        Abi::GetSymbolForStage(Abi::PipelineSymbolType::ShaderMainEntry, pInfo->stageId));
                PAL_ASSERT(symbol.size == pInfo->codeLength);

                const void* pCodeSection   = nullptr;
                size_t      codeSectionLen = 0;
                abiProcessor.GetPipelineCode(&pCodeSection, &codeSectionLen);
                PAL_ASSERT((symbol.size + symbol.value) <= codeSectionLen);

                memcpy(pBuffer,
                       VoidPtrInc(pCodeSection, static_cast<size_t>(symbol.value)),
                       static_cast<size_t>(symbol.size));
            }
        }
        else
        {
            result = Result::ErrorInvalidMemorySize;
        }
    }

    return result;
}

// =====================================================================================================================
// Extracts the performance data from GPU memory and copies it to the specified buffer.
Result Pipeline::GetPerformanceData(
    Util::Abi::HardwareStage hardwareStage,
    size_t*                  pSize,
    void*                    pBuffer)
{
    Result       result       = Result::ErrorUnavailable;
    const uint32 index        = static_cast<uint32>(hardwareStage);
    const auto&  perfDataInfo = m_perfDataInfo[index];

    if (pSize == nullptr)
    {
        result = Result::ErrorInvalidPointer;
    }
    else if (perfDataInfo.sizeInBytes > 0)
    {
        if (pBuffer == nullptr)
        {
            (*pSize) = perfDataInfo.sizeInBytes;
            result   = Result::Success;
        }
        else if ((*pSize) >= perfDataInfo.sizeInBytes)
        {
            void* pData = nullptr;
            result = m_gpuMem.Map(&pData);

            if (result == Result::Success)
            {
                memcpy(pBuffer, VoidPtrInc(pData, perfDataInfo.cpuOffset), perfDataInfo.sizeInBytes);
                result = m_gpuMem.Unmap();
            }
        }
    }

    return result;
}

// =====================================================================================================================
// Helper method which extracts shader statistics from the pipeline ELF binary for a particular hardware stage.
Result Pipeline::GetShaderStatsForStage(
    const ShaderStageInfo& stageInfo,
    const ShaderStageInfo* pStageInfoCopy, // Optional: Non-null if we care about copy shader statistics.
    ShaderStats*           pStats
    ) const
{
    PAL_ASSERT(pStats != nullptr);
    memset(pStats, 0, sizeof(ShaderStats));

    // We can re-parse the saved pipeline ELF binary to extract shader statistics.
    AbiProcessor abiProcessor(m_pDevice->GetPlatform());
    Result result = abiProcessor.LoadFromBuffer(m_pPipelineBinary, m_pipelineBinaryLen);

    MsgPackReader      metadataReader;
    CodeObjectMetadata metadata;

    if (result == Result::Success)
    {
        result = abiProcessor.GetMetadata(&metadataReader, &metadata);
    }

    if (result == Result::Success)
    {
        const auto& stageMetadata = metadata.pipeline.hardwareStage[static_cast<uint32>(stageInfo.stageId)];

        pStats->common.numUsedSgprs = stageMetadata.sgprCount;
        pStats->common.numUsedVgprs = stageMetadata.vgprCount;

        pStats->numAvailableSgprs = stageMetadata.sgprLimit;
        pStats->numAvailableVgprs = stageMetadata.vgprLimit;

        pStats->common.ldsUsageSizeInBytes    = stageMetadata.ldsSize;
        pStats->common.scratchMemUsageInBytes = stageMetadata.scratchMemorySize;

        pStats->isaSizeInBytes = stageInfo.disassemblyLength;

        if (pStageInfoCopy != nullptr)
        {
            const auto& copyStageMetadata =
                metadata.pipeline.hardwareStage[static_cast<uint32>(pStageInfoCopy->stageId)];

            pStats->flags.copyShaderPresent = 1;

            pStats->copyShader.numUsedSgprs = copyStageMetadata.sgprCount;
            pStats->copyShader.numUsedVgprs = copyStageMetadata.vgprCount;

            pStats->copyShader.ldsUsageSizeInBytes    = copyStageMetadata.ldsSize;
            pStats->copyShader.scratchMemUsageInBytes = copyStageMetadata.scratchMemorySize;
        }
    }

    return result;
}

// =====================================================================================================================
// Calculates the size, in bytes, of the performance data buffers needed total for the entire pipeline.
size_t Pipeline::PerformanceDataSize(
    const CodeObjectMetadata& metadata
    ) const
{
    size_t dataSize = 0;

    for (uint32 i = 0; i < static_cast<uint32>(Abi::HardwareStage::Count); i++)
    {
        dataSize += metadata.pipeline.hardwareStage[i].perfDataBufferSize;
    }

    return dataSize;
}

// =====================================================================================================================
void Pipeline::DumpPipelineElf(
    const AbiProcessor& abiProcessor,
    const char*         pPrefix,
    const char*         pName         // Optional: Non-null if we want to use a human-readable name for the filename.
    ) const
{
#if PAL_ENABLE_PRINTS_ASSERTS
    const PalSettings& settings = m_pDevice->Settings();
    uint64 hashToDump = settings.pipelineLogConfig.logPipelineHash;
    bool hashMatches = ((hashToDump == 0) || (m_info.compilerHash == hashToDump));

    const bool dumpInternal  = settings.pipelineLogConfig.logInternal;
    const bool dumpExternal  = settings.pipelineLogConfig.logExternal;
    const bool dumpPipeline  =
        (hashMatches && ((dumpExternal && !IsInternal()) || (dumpInternal && IsInternal())));

    if (dumpPipeline)
    {
        const char*const pLogDir = &settings.pipelineLogConfig.pipelineLogDirectory[0];

        char fileName[512] = { };
        if ((pName == nullptr) || (pName[0] == '\0'))
        {
            Snprintf(&fileName[0], sizeof(fileName), "%s/%s_0x%016llX.elf", pLogDir, pPrefix, m_info.compilerHash);
        }
        else
        {
            Snprintf(&fileName[0], sizeof(fileName), "%s/%s_%s.elf", pLogDir, pPrefix, pName);
        }

        File file;
        file.Open(fileName, FileAccessWrite | FileAccessBinary);
        file.Write(m_pPipelineBinary, m_pipelineBinaryLen);
    }
#endif

    PipelineDumpService* pDumpService = m_pDevice->GetPlatform()->GetPipelineDumpService();
    if (pDumpService != nullptr)
    {
        pDumpService->RegisterPipeline(m_pPipelineBinary,
                                       static_cast<uint32>(m_pipelineBinaryLen),
                                       m_info.compilerHash);
    }
}

} // Pal
